---
# This is just default ansible parsed file for hosts  <<<<<<<<<<DRAFT Placeholder>>>>>>>
# v0.01 20210802
# file: /hosts.yml
# Global Hosts files for group structure
# Ex: ansible-playbook ./roles/role_ping_nodes.yml --limit power_hosts
# Note: Setting for each host group and variables for each group or host we can set. 
all:
  children:
###### Physical HyperConverge Server Devices for environment ###########
    power_hosts: # Nodes for hosting VMs
      hosts:
        p90061:
          mgmt_nic: enp8s0f0 # Set in Kickstart OS install
          storage_nic: ens15f0
          mgmt_ip: enp8s0f1
          storage_ip: 172.16.101.101
          bmc_ip: 172.16.101.101
          # boot_disk: ata-Samsung_SSD_850_PRO_512GB_S250NXAGA15787L # ls -al /dev/disk/by-id/ |grep sdb 
          # data00_disk: WDC_WDS100T2B0B-00YS70_192490801828 # ls -al /dev/disk/by-id/ |grep sdc ##But VDO needs mapper device for gpt so /dev/mapper/
          # data01_disk: WDC_WDS100T2B0B-00YS70_19106A802926 # ls -al /dev/disk/by-id/ |grep sdd ##But VDO needs mapper device for gpt so /dev/mapper/
        p84861:
          mgmt_nic: enp8s0f0 # Set in Kickstart OS install
          storage_nic: ens15f0
          mgmt_ip: enp8s0f1
          storage_ip: 172.16.101.102
          bmc_ip: 172.16.101.101
          # boot_disk: ata-Micron_1100_MTFDDAV512TBN_17401F699137 # ls -al /dev/disk/by-id/ |grep sdb 
          # data00_disk: WDC_WDS100T2B0B-00YS70_183533804564 # ls -al /dev/disk/by-id/ |grep sdc ##But VDO needs mapper device for gpt so /dev/mapper/
          # data01_disk: nvme.126f-4141303030303030303030303030303032343538-53504343204d2e32205043496520535344-00000001 # ls -al /dev/disk/by-id/ |grep nvme0n1 ##But VDO needs mapper device for gpt so /dev/mapper/
        p80051:
          mgmt_nic: enp7s0 # Set in Kickstart OS install
          storage_nic: enp3s0f0
          mgmt_ip: enp3s0f2
          storage_ip: 172.16.101.103
          bmc_ip: 172.16.101.101
          # boot_disk: ata-SAMSUNG_SSD_PM851_mSATA_512GB_S1EWNYAF609306 # ls -al /dev/disk/by-id/ |grep sdb 
          # data00_disk: WDC_WDS100T2B0B-00YS70_19106A800900 # ls -al /dev/disk/by-id/ |grep sdc ##But VDO needs mapper device for gpt so /dev/mapper/
          # data01_disk: WDC_WDS100T2B0B_2013EP442601 # ls -al /dev/disk/by-id/ |grep sdd ##But VDO needs mapper device for gpt so /dev/mapper/
        #eir:
      vars:
        ansible_ssh_pass: "{{ vault_ansible_sudo_password }}"
        hci_ignition_node: pvc01
        # gluster_brick_data00: data00
        # gluster_brick_dir: /gluster_bricks/
    ibm_storage: # Nodes for hosting VMs Private LAN side
      hosts:
        fs72001:
          mgmt0_ip: 172.20.10.245 # Storewize Cannister A Mgmt IP
          mgmt1_ip: 172.20.10.35 # Storewize Cannister B Mgmt IP
          service0_ip: 172.20.10.36 # Storewize Cannister A service IP
          service1_ip: 172.20.10.37 # Storewize Cannister B service IP
          iscsi0_ip: 172.20.10.32 # Storewize Cannister A iSCSI IP
          iscsi1_ip: 172.20.10.33 # Storewize Cannister B iSCSI IP       
        fs9001:
          mgmt0_ip: 172.20.10.210 # VIP Mgmt IP
          service0_ip: 172.20.10.211 # Cannister A service IP
          service1_ip: 172.20.10.212 # Cannister B service IP
      vars:
        ansible_ssh_pass: "{{ vault_ansible_sudo_password }}"
        storage_ssh_key: "{{ vault_storage_ssh_key }}"
    ibm_intel_vmware: # Intel vmware cluster nodes
      hosts:
        x385001:
          mgmt_nic0: en0 # dvSwitch0 for mgmt, vmotion, vms
          mgmt_nic1: en0 # dvSwitch0 for mgmt, vmotion, vms
          storage_nic2: en2 # iSCSI / ROCE for block data
          storage_nic3: en3 # iSCSI / ROCE for block data
          mgmt_ip: 172.20.11.197
          storage_ip0: 172.20.18.196
          storage_ip1: 172.20.19.196
          ipmi_ip: 172.20.11.196
        x385002:
          mgmt_nic0: en0 # dvSwitch0 for mgmt, vmotion, vms
          mgmt_nic1: en0 # dvSwitch0 for mgmt, vmotion, vms
          storage_nic2: en2 # iSCSI / ROCE for block data
          storage_nic3: en3 # iSCSI / ROCE for block data
          mgmt_ip: 172.20.11.199
          storage_ip0: 172.20.18.198
          storage_ip1: 172.20.19.198
          ipmi_ip: 172.20.11.198
    ibm_intel_windows: # Intel windows bastion nodes
      hosts:
        x325001:
          mgmt_nic0: en0 # dvSwitch0 for mgmt, vmotion, vms
          mgmt_nic1: en0 # dvSwitch0 for mgmt, vmotion, vms
          storage_nic2: en2 # iSCSI / ROCE for block data
          storage_nic3: en3 # iSCSI / ROCE for block data
          mgmt_ip: 172.20.11.213
          storage_ip0: 172.20.11.214
          storage_ip1: 172.20.19.42
          ipmi_ip: 172.20.11.215
        x325002:
          mgmt_nic0: en0 # dvSwitch0 for mgmt, vmotion, vms
          mgmt_nic1: en0 # dvSwitch0 for mgmt, vmotion, vms
          storage_nic2: en2 # iSCSI / ROCE for block data
          storage_nic3: en3 # iSCSI / ROCE for block data
          mgmt_ip: 172.20.11.216
          storage_ip0: 172.20.11.217
          storage_ip1: 172.20.19.43
          ipmi_ip: 172.20.11.218
    group_ibm_intel_total:
      ibm_intel_vmware:
      ibm_intel_windows:
###### Power VC VM engine ##########
    pvc_engine:
      hosts:
        pvc01:
###### VM based Control Plane for environment ###########
    idm_nodes: # Nodes for cluster RBAC of Identity Managment Cluster
      hosts:
        ibmdc01:
        ibmdc02:
    bastion_node: # Host to deploy and run installations / ansible jobs
      hosts:
        ansible00:
###### Network Devices for environment ###########
    group_cisco: # Cisco Nexus 5k and leafs
      hosts:
        sw10:  # use /group_vars/group_cisco.yml instead 
          # ssh_key: AAAAB3NzaC1yc2EAAAADAQABAAAAgQC0zRUpJ+eF8b6sEd43rdahwYutZ2cedOywituGmpPBgMjpllxZcyVlfN2h+TxeqAyu1nw4qZJjE7qMatuCejHbUTkIC1hhZJEpVUooD8HzvkZiBtgl5eLFI3dMFe4poLU1aFQ+kecK+4jyz7u42Mh87DqvUnQNrzKfZPjXJaBdDw==
          #ansible_host: 1.1.1.1  # Put this in if no DNS
          # ansible_connection: ansible.netcommon.network_cli
          # ansible_network_os: cisco.nxos.nxos  
          # ansible_user: ansible
          # ansible_pass: "{{ vault_ansible_sudo_password }}"
        sw11:
    group_mellanox: # Mellanox 25/100Gb switches
        hosts:
          fabsw1a:
          fabsw1b:
    group_1gb: # 1Gb switches off of Mellanox
        hosts:
          fabsw1a1:
          fabsw1b1:
    group_vdx: # Brocade VDX Stack
      hosts:
        vsw10: # Stack cluster VIP
        # sw12: 
        # sw13:
        # sw20:
        # sw26:
      group_switches: # All Network switches in environment
        children:
          group_cisco:
          group_mellanox:
          group_1gb:
          group_vdx:
###### Power and Temprature Control Plane for environment ###########
    group_ups:  # UPS in environment
      hosts:
        ups01:
    group_ups_client: # VM Clients who connect to each UPS unit with varible set to which UPS they are slaved
      hosts:
        pvc01:
         vars:
           ups: "{{ ups01 }}"
        vcenter01:
         vars:
           ups: "{{ ups01 }}"
        ansible00:
         vars:
           ups: "{{ ups01 }}"
