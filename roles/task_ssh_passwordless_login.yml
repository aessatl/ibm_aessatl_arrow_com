---
# This role is for internode passwordless login. Passwordless login between all hosts listed in /etc/hosts which is the master infrastructure resources. 
# v1.0 20210222
# file: /roles/task_ssh_passwordless_login.yml
#  
- name: Install ssh tools to cross ssh setup to nodes in cluster 
  yum:
    name: 
    - openssh-clients
    - sshpass
    state: latest
  become: true
# Check if user has ssh key generated. If not. Create
- name: Create a 2048-bit SSH key for user {{ansible_user_id}}
  ansible.builtin.user:
    name: root
    generate_ssh_key: yes
    ssh_key_bits: 2048
    ssh_key_file: .ssh/id_rsa

# Create total list.  IP,short name and long name 
# Broken: Does not resolve short names. Creates massive timeouts if host is not up to crawl through entire ssh list. 
# This has to be done after bridges finished as MACs change.
- name: Dump all hosts out of /etc/hosts into temp file /tmp/hosts.out
  shell: "grep -v '^#' /etc/hosts | xargs -n1 > /tmp/hosts.out"
- name: Run ssh-keyscan and sshpass against list of hosts
  shell: for vm in $(cat /tmp/hosts.out); do ssh-keyscan -H "$vm" >> ~/.ssh/known_hosts; sshpass -p "{{ vault_ansible_sudo_password }}" ssh-copy-id -i ~/.ssh/id_rsa.pub ansible@"$vm"; done



















####################
# task: 
#  - hosts: all
#    vars: # ssh password for cluster environt Ex: Created from shell of ansible bastion node via "mkpasswd --method=SHA-512"
#      - ansible_password: '$6$oXPZpzeM$5pF8IVwiLW8gTiFc4lHgN5EYhHBU8XDsGMQS3fy.gkd20rZATdoojeEqw4r.48.Lbd0r5vGok7ZHInZME5GJM.'
#   gather_facts: no
#    remote_user: root
 
#    tasks:
 
#    - name: Add a new user named ansible
#      user:
#           name=ansible
#           password={{ ansible_password }}
 
#    - name: Add ansible user to the sudoers
#      copy:
#           dest: "/etc/sudoers.d/ansible"
#           content: "ansible  ALL=(ALL)  NOPASSWD: ALL"
 
#    - name: Deploy SSH Key
#      authorized_key: user=ansible
#                      key="{{ lookup('file', '/home/ansible/.ssh/id_rsa.pub') }}"
#                      state=present
 
#    - name: Disable Password Authentication
#      lineinfile:
#            dest=/etc/ssh/sshd_config
#            regexp='^PasswordAuthentication'
#            line="PasswordAuthentication no"
#            state=present
#            backup=yes
#      notify:
#        - restart ssh
# #  # Good option but for my cluster I decided to not do this
# #    - name: Disable Root Login
# #      lineinfile:
# #            dest=/etc/ssh/sshd_config
# #            regexp='^PermitRootLogin'
# #            line="PermitRootLogin no"
# #            state=present
# #            backup=yes
#      notify:
#        - restart ssh
 
#    handlers:
#    - name: restart ssh
#      service:
#        name=sshd
#        state=restarted


########## Draft notes and ideas #######
# # https://docs.ansible.com/ansible/latest/user_guide/connection_details.html 
# [defaults]
# host_key_checking = False

# ### SSH from ansible bastion node to host/group <<< Broken>>>>
# # if "ping fails to host"
# task:
#   - name: Ansible ping node to test existing passwordless login working
#   # Pull cluster password from ansible vault vs file / input
#   # --vault-id 
  
# # then "run shell command to add host"
# sshpass -f /home/ansible/sshpassword ssh-copy-id ansible@172.16.100.101  -oStrictHostKeyChecking=no
# # else "lookup all other nodes within cluster and make sure keyless login works"
# tasks:
#     - name: Add host to allow SSH from bastion node issuing ansible
#     - command: "sh /home/aravind/downtime.sh {{my_hostname}} {{my_duration}} {{my_comments}}"
# # Assumes user cluster is created.  
# - task:
#   - name: ssh from hosts add to local keyless password login
#     shell: sshpass -f /home/ansible/sshpassword ssh-copy-id ansible@{{all}}  -oStrictHostKeyChecking=no

# Notes from https://www.theurbanpenguin.com/using-ansible-playbooks/
## <<< Broken>>>
# - name: Deploy Local User SSH Key for user cluster
#   authorized_key:
#   user: cluster
#   state: present
#   manage_dir: true
#   key: "{{ lookup('file', '/home/tux/.ssh/id_rsa.pub') }}" #Not sure if this is validating key file exists or copy over. common public key to use across cluster

# - name: Allow user cluster to run sudo commands
# copy:
# dest: /etc/sudoers.d/cluster
# content: 'cluster ALL=(ALL) NOPASSWD: ALL' 
# validate: /usr/sbin/visudo -cf %s


# # Ansible Host Automation Admin examples  https://opensource.com/article/17/7/automate-sysadmin-ansible
# # The assumption here is a cluster wide ssh key is saved for each site "production" "staging"
# - hosts: all
#   gather_facts: false
#   vars:
#     ssh_key: /production/ssh_cluster_keys
#   tasks:
#     - name: copy ssh key
#       authorized_key:
#         key: "{{ lookup('file', ssh_key) }}"
#         user: root

# # Another example
# ---
# - hosts: all
#   gather_facts: true
#   vars:
#   tasks:
#     - name: Enabling ssh-key only root access
#       lineinfile:
#         dest: /etc/ssh/sshd_config
#         regexp: '^PermitRootLogin'
#         line: 'PermitRootLogin without-password'
#       notify:
#         - restart_sshd
#         - restart_ssh

#   handlers:
#     - name: restart_sshd
#       service:
#         name: sshd
#         state: restarted
#         enabled: true
#       when: ansible_distribution == 'RedHat'
#     - name: restart_ssh
#       service:
#         name: ssh
#         state: restarted
#         enabled: true
#       when: ansible_distribution == 'Debian'